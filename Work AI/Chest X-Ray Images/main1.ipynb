{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **98% Accuracy - Chest X-ray Images (Pneumonia or Normal) Classification using CNN**\n",
    "![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13369-021-06127-z/MediaObjects/13369_2021_6127_Fig2_HTML.png)\n",
    "\n",
    "\n",
    "   **98% Accuracy in Predicting if the X-ray is of a Pneumonia Patient or not**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Importing and labeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import warnings\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "Train_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/'\n",
    "Test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/'\n",
    "Val_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/'\n",
    "\n",
    "\n",
    "Categories = os.listdir(Train_dir)\n",
    "print(\"Train\",Categories, \"0 is Pneumonia and 1 is Normal\")\n",
    "\n",
    "\n",
    "\n",
    "img_size = 150\n",
    "def create_data(dir):\n",
    "    data = []\n",
    "    for d in os.listdir(dir):\n",
    "        path_dir = os.path.join(dir,d)\n",
    "        class_num = Categories.index(d)\n",
    "        for file in os.listdir(path_dir):\n",
    "            img_array = cv2.imread(os.path.join(path_dir,file), cv2.IMREAD_GRAYSCALE)\n",
    "            new_img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            data.append([new_img_array, class_num])\n",
    "    return data\n",
    "training_data = create_data(Train_dir)\n",
    "testing_data = create_data(Test_dir)\n",
    "validation_data = create_data(Val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Shuffling the data so that random samples are provided to the model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for features,labels in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(labels)\n",
    "print(X_train[:1], y_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Plotting a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for img,label in zip(X_train[:2], y_train[:2]):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(Categories[label])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Reshaping and converting X and y to numpy arrays for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X = np.array(X_train).reshape(-1, img_size,img_size, 1)\n",
    "X = X / 255.0\n",
    "y = np.array(y_train)\n",
    "print(X[:1], y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv2D, MaxPool2D, Dropout, Flatten, LeakyReLU\n",
    "\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv2D(32, (3,3), padding = 'same', input_shape=X.shape[1:]))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "Model.add(Conv2D(64, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "Model.add(Conv2D(96, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Conv2D(128, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Conv2D(256, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Conv2D(320, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Conv2D(320, (3,3), padding = 'same'))\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "Model.add(Flatten())\n",
    "\n",
    "Model.add(Dense(256))\n",
    "Model.add(Activation('relu'))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64))\n",
    "Model.add(Activation('relu'))\n",
    "# Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(32))\n",
    "Model.add(Activation('relu'))\n",
    "\n",
    "Model.add(Dense(1))\n",
    "Model.add(Activation('sigmoid'))\n",
    "\n",
    "Model.summary()\n",
    "\n",
    "Model.compile(loss = 'binary_crossentropy', optimizer = 'RMSprop', metrics=['accuracy'])\n",
    "\n",
    "History = Model.fit(X, y, batch_size = 64, epochs = 10,validation_split = 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = History.history['accuracy']\n",
    "val_acc = History.history['val_accuracy']\n",
    "\n",
    "# Retrieve a list of loss results on training and validation data\n",
    "loss = History.history['loss']\n",
    "val_loss = History.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "# Plot training and validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for X, y in validation_data:\n",
    "    X_val.append(X)\n",
    "    y_val.append(y)\n",
    "    \n",
    "\n",
    "\n",
    "X_val = np.array(X_val).reshape(-1, img_size,img_size, 1)\n",
    "X_val = X_val / 255.0\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "Val_Eval = Model.evaluate(X_val, y_val, batch_size = 32)\n",
    "Val_Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for X, y in testing_data:\n",
    "    X_test.append(X)\n",
    "    y_test.append(y)\n",
    "    \n",
    "\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, img_size,img_size, 1)\n",
    "X_test = X_test / 255.0\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "Test_Eval = Model.evaluate(X_test, y_test, batch_size = 32)\n",
    "Test_Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# sklearn.metrics.mean_squared_error\n",
    "y_pred_test = Model.predict(X_test)\n",
    "y_pred_val = Model.predict(X_val)\n",
    "\n",
    "MSE_val = mean_squared_error(y_val, y_pred_val)\n",
    "MSE_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Mean Squared Error\")\n",
    "print(\"Validation Set: \", MSE_val, \"Testing Set: \", MSE_test)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
